{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce76f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import yaml\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95b34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef8523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'C:/Users/amnar/Desktop/gh_konsistensi/'\n",
    "yaml_path = 'ref/stb_config_all_2021.yml'\n",
    "\n",
    "# File paths\n",
    "dataset_path = base_path + 'data/stb/JR4M09Y2021_DATA RAW.xlsx'\n",
    "reference_files = ['ref/oku.csv',\n",
    "                   'ref/kewarganegaraan.csv',\n",
    "                   'ref/kumpulan_etnik.csv', \n",
    "                   'ref/persekolahan.csv',\n",
    "                   'ref/pendidikan_rasmi.csv',\n",
    "                   'ref/pendidikan_rasmi_tertinggi_2022.csv', \n",
    "                   'ref/sijil_tertinggi.csv',\n",
    "                   'ref/sijil_tertinggi_2022.csv',\n",
    "                   'ref/status_code.csv', \n",
    "                   'ref/msic_code_detail_01.csv',\n",
    "                   'ref/masco_code.csv',\n",
    "                   'ref/negara_code.csv', \n",
    "                   'ref/institusi_pengajian.csv',\n",
    "                   'ref/bidang_pengajian.csv']\n",
    "\n",
    "file_paths = [dataset_path] + [base_path + file for file in reference_files]\n",
    "yaml_file = base_path + yaml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473d4d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amnar\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "def read_files(*file_paths):\n",
    "    def read_csv(file_path):\n",
    "        return pd.read_csv(file_path, encoding='unicode_escape', low_memory=False)\n",
    "\n",
    "    def read_excel(file_path):\n",
    "        workbook = load_workbook(filename=file_path)\n",
    "        sheet_name = workbook.sheetnames[0]  # Get the name of the first sheet\n",
    "        worksheet = workbook[sheet_name]\n",
    "        data = list(worksheet.values)\n",
    "        return pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "    file_readers = {\n",
    "        'csv': read_csv,\n",
    "        'xlsx': read_excel,\n",
    "        'xls': read_excel\n",
    "    }\n",
    "    \n",
    "    predefined_names = {\n",
    "        'JR4M09Y2021_DATA RAW.xlsx': 'df',\n",
    "        'oku.csv': 'df_oku',\n",
    "        'kewarganegaraan.csv': 'df_kw',\n",
    "        'kumpulan_etnik.csv': 'df_ket',\n",
    "        'persekolahan.csv': 'df_persk',\n",
    "        'pendidikan_rasmi.csv': 'df_pend',\n",
    "        'pendidikan_rasmi_tertinggi_2022.csv': 'df_pend_22',\n",
    "        'sijil_tertinggi.csv': 'df_sijil',\n",
    "        'sijil_tertinggi_2022.csv': 'df_sijil_22',\n",
    "        'status_code.csv': 'df_status',\n",
    "        'msic_code_detail_01.csv': 'df_msic',\n",
    "        'masco_code.csv': 'df_masco',\n",
    "        'negara_code.csv': 'df_ngra',\n",
    "        'institusi_pengajian.csv': 'df_ip',\n",
    "        'bidang_pengajian.csv': 'df_fs'\n",
    "    }\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = file_path.split('/')[-1]\n",
    "        df_name = predefined_names[filename]\n",
    "        file_format = filename.split('.')[-1]\n",
    "        \n",
    "        # Declare the dataframe name as global\n",
    "        globals()[df_name] = file_readers[file_format](file_path)\n",
    "\n",
    "# Call the function\n",
    "read_files(*file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3ec127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the YAML file\n",
    "with open(yaml_file, 'r') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Extract conditions from the YAML data\n",
    "persekolahan = config['persekolahan']\n",
    "\n",
    "# Create an empty dictionary to store the merged values\n",
    "merged_conditions = {}\n",
    "\n",
    "# Loop over the persekolahan dictionaries and merge the values\n",
    "for key, conditions in persekolahan.items():\n",
    "    merged_conditions[key] = {}\n",
    "    for condition_key, condition_value in conditions.items():\n",
    "        if condition_key == 'U':\n",
    "            if isinstance(condition_value, str) and condition_value.isdigit():\n",
    "                condition_value = int(condition_value)\n",
    "        merged_conditions[key][condition_key] = condition_value\n",
    "        \n",
    "for key in persekolahan:\n",
    "    persekolahan[key]['U'] = list(eval(persekolahan[key]['U']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "549c0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the dataset name from the file path\n",
    "# dataset_name = os.path.basename(dataset_path)\n",
    "\n",
    "# # Extract the first three characters\n",
    "# doc_type = dataset_name[:3]\n",
    "\n",
    "# # Extract the characters at index 3 and 4\n",
    "# quarter_ref = dataset_name[3:5]\n",
    "\n",
    "# # Extract the characters from index 6 to 9\n",
    "# year_ref = int(dataset_name[5:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd0748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the string \"None\" (and its variants with potential spaces) with NaN for the entire DataFrame\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: np.nan if str(x).strip() == 'None' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e56d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted S18 to have 6 digits with leading zeros.\n",
      "Formatted S19 to have 5 digits with leading zeros.\n",
      "Converted RIN to <class 'int'>.\n",
      "Formatted KOD_MASCO to have 6 digits with leading zeros.\n",
      "Formatted KOD_MSIC to have 5 digits with leading zeros.\n",
      "Column 'Kod' not found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "def format_columns(data, columns_to_format):\n",
    "    # Standardize columns with 6 digits and leading zeros\n",
    "    for column in columns_to_format['leading_zeros_6_digits']:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].apply(lambda x: str(int(x)).zfill(6) if not pd.isnull(x) else x)\n",
    "            print(f\"Formatted {column} to have 6 digits with leading zeros.\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "    # Standardize columns with 5 digits and leading zeros\n",
    "    for column in columns_to_format['leading_zeros_5_digits']:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].apply(lambda x: str(int(x)).zfill(5) if not pd.isnull(x) else x)\n",
    "            print(f\"Formatted {column} to have 5 digits with leading zeros.\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "            \n",
    "    # Standardize columns with 5 digits and leading zeros\n",
    "    for column in columns_to_format['leading_zeros_4_digits']:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].apply(lambda x: str(int(x)).zfill(4) if not pd.isnull(x) else x)\n",
    "            print(f\"Formatted {column} to have 4 digits with leading zeros.\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "            \n",
    "    # Standardize columns with 3 digits and leading zeros\n",
    "    for column in columns_to_format['leading_zeros_3_digits']:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].apply(lambda x: str(int(x)).zfill(3) if not pd.isnull(x) else x)\n",
    "            print(f\"Formatted {column} to have 3 digits with leading zeros.\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "            \n",
    "    # Standardize columns with 2 digits and leading zeros\n",
    "    for column in columns_to_format['leading_zeros_2_digits']:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].apply(lambda x: str(int(x)).zfill(2) if not pd.isnull(x) else x)\n",
    "            print(f\"Formatted {column} to have 2 digits with leading zeros.\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "    # Convert columns to specific formats\n",
    "    for column, data_type in columns_to_format['data_types'].items():\n",
    "        if column in data.columns:\n",
    "            if data_type == int:\n",
    "                data[column] = data[column].apply(lambda x: int(x) if pd.notnull(x) and str(x).isdigit() else x)\n",
    "                print(f\"Converted {column} to {data_type}.\")\n",
    "            else:\n",
    "                data[column] = data[column].astype(data_type)\n",
    "                print(f\"Converted {column} to {data_type}.\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "    # Standardize columns with 7 digits and two decimal places (string)\n",
    "    for column in columns_to_format['standardize_7_digits']:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].apply(lambda x: f\"{float(x):08.2f}\" if pd.notnull(x) and (isinstance(x, float) or (isinstance(x, str) and x.replace('.', '', 1).isdigit())) else x)\n",
    "            print(f\"Standardized {column} to have 7 digits and two decimal places.\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "    # Return the modified DataFrame\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "columns_to_format_01 = {\n",
    "    'leading_zeros_6_digits': ['S18'],\n",
    "    'leading_zeros_5_digits': ['S19'],\n",
    "    'leading_zeros_4_digits': [],\n",
    "    'leading_zeros_3_digits': [],\n",
    "    'leading_zeros_2_digits': [],\n",
    "    'standardize_7_digits': [],\n",
    "    'data_types': {'RIN': int\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "columns_to_format_02 = {\n",
    "    'leading_zeros_6_digits': ['KOD_MASCO'],\n",
    "    'leading_zeros_5_digits': [],\n",
    "    'leading_zeros_4_digits': [],\n",
    "    'leading_zeros_3_digits': [],\n",
    "    'leading_zeros_2_digits': [],\n",
    "    'standardize_7_digits': [],\n",
    "    'data_types': {\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "columns_to_format_03 = {\n",
    "    'leading_zeros_6_digits': [],\n",
    "    'leading_zeros_5_digits': ['KOD_MSIC'],\n",
    "    'leading_zeros_4_digits': [],\n",
    "    'leading_zeros_3_digits': [],\n",
    "    'leading_zeros_2_digits': [],\n",
    "    'standardize_7_digits': [],\n",
    "    'data_types': {\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "columns_to_format_04 = {\n",
    "    'leading_zeros_6_digits': ['Kod'],\n",
    "    'leading_zeros_5_digits': [],\n",
    "    'leading_zeros_4_digits': [],\n",
    "    'leading_zeros_3_digits': [],\n",
    "    'leading_zeros_2_digits': [],\n",
    "    'standardize_7_digits': [],\n",
    "    'data_types': {\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "formatted_data_01 = format_columns(df, columns_to_format_01)\n",
    "formatted_data_02 = format_columns(df_masco, columns_to_format_02)\n",
    "formatted_data_03 = format_columns(df_msic, columns_to_format_03)\n",
    "formatted_data_04 = format_columns(df_status, columns_to_format_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5f4e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S18</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111101</td>\n",
       "      <td>GOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111102</td>\n",
       "      <td>GOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111103</td>\n",
       "      <td>GOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111104</td>\n",
       "      <td>GOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111106</td>\n",
       "      <td>GOV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      S18 STATUS\n",
       "0  111101    GOV\n",
       "1  111102    GOV\n",
       "2  111103    GOV\n",
       "3  111104    GOV\n",
       "4  111106    GOV"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_status.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.head(500)\n",
    "print(df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea61027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = df.columns[df.columns.str.startswith(\"MASCO\")]\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac31af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78976aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list = df_kw[\"Kod\"].astype(str).apply(lambda x: x.zfill(3)).tolist()\n",
    "ket_list = list(map(int, df_ket.iloc[:97][\"Kod\"].values))\n",
    "status_list = df_status[\"S18\"].values.tolist()\n",
    "masco_list = df_masco[\"KOD_MASCO\"].values.tolist()\n",
    "msic_list = df_msic[\"KOD_MSIC\"].values.tolist()\n",
    "pkis_list = [str(i).zfill(2) for i in range(1, 13)]\n",
    "no_kel_list = [str(i).zfill(3) for i in range(1, 1000)]\n",
    "ngri_list = df_ngra[\"KOD\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Semakan Julat JR4 ###\n",
    "\n",
    "kel_list = list(range(1000))\n",
    "b_list = list(range(13))\n",
    "ng_list = list(range(17))\n",
    "dp_list = list(range(32))\n",
    "db_list = list(range(170))\n",
    "db2_list = set(str(i).zfill(5) for i in range(1, 100000))\n",
    "st_list = list(range(10))\n",
    "notk_list = list(range(1000))\n",
    "noir_list = list(range(100))\n",
    "t_list = list(range(100))\n",
    "pkis_list = [str(i).zfill(2) for i in range(1, 13)]\n",
    "hmis_list = [str(i).zfill(2) for i in range(1, 100)]\n",
    "bk_list = [str(i).zfill(2) for i in range(1, 13)]\n",
    "tk_list = [str(i).zfill(4) for i in range(1900, 3000)]\n",
    "u_list = list(range(201))\n",
    "tp_list = list(range(6))\n",
    "ngri_list = [str(i).zfill(2) for i in range(1, 17)] + ['98']\n",
    "ngra_list = df_ngra[\"KOD\"].astype(str).apply(lambda x: x.zfill(3)).tolist()\n",
    "oku_list = df_oku[\"Kod\"].astype(str).apply(lambda x: x.zfill(2)).tolist()\n",
    "pt_22_list = df_pend_22[\"KOD\"].astype(str).apply(lambda x: x.zfill(3)).tolist()\n",
    "sj_22_list = df_sijil_22[\"KOD\"].astype(str).apply(lambda x: x.zfill(3)).tolist()\n",
    "ip_list = df_ip[\"Kod\"].tolist()\n",
    "fs_list = df_fs[\"Kod\"].astype(str).apply(lambda x: x.zfill(4)).tolist()\n",
    "hmwa_list = list(range(100))\n",
    "\n",
    "def validate_all_julats(row):\n",
    "    row['JULAT_001'] = 1 if row['NOKEL'] in no_kel_list else 0\n",
    "    row['JULAT_002'] = 1 if row['B'] in b_list else 0\n",
    "    row['JULAT_003'] = 1 if row['NG'] in ng_list else 0\n",
    "    row['JULAT_004'] = 1 if row['DP'] in dp_list else 0\n",
    "    row['JULAT_005'] = 1 if row['DB'] in db_list else 0\n",
    "    row['JULAT_006'] = 1 if row['BP'] in db_list else 0\n",
    "    row['JULAT_007'] = 1 if row['BP2'] in db2_list else 0\n",
    "    row['JULAT_008'] = 1 if row['ST'] in st_list else 0\n",
    "    row['JULAT_009'] = 1 if row['NOTK'] in notk_list else 0\n",
    "    row['JULAT_010'] = 1 if row['NOIR'] in noir_list else 0\n",
    "    row['JULAT_011'] = 1 if row['JR'] == 4 else 0\n",
    "    row['JULAT_012'] = 1 if isinstance(row['NAMA'], str) and len(row['NAMA']) <= 50 else 0\n",
    "    row['JULAT_013'] = 1 if isinstance(row['NOIC'], str) and len(row['NOIC']) <= 12 or pd.isna(row['NOIC']) else 0\n",
    "    row['JULAT_014'] = 1 if row['PKIS'] in pkis_list else 0\n",
    "    row['JULAT_015'] = 1 if row['HMIS'] in hmis_list else 0\n",
    "    row['JULAT_016'] = 1 if row['J'] in [1, 2] else 0\n",
    "    row['JULAT_017'] = 1 if row['BK'] in bk_list else 0\n",
    "    row['JULAT_018'] = 1 if row['TK'] in tk_list else 0\n",
    "    row['JULAT_019'] = 1 if row['U'] in u_list else 0\n",
    "    row['JULAT_020'] = 1 if row['KET'] in ket_list else 0\n",
    "    row['JULAT_021'] = 1 if row['KW'] in kw_list else 0\n",
    "    row['JULAT_022'] = 1 if row['TP'] in tp_list else 0\n",
    "    row['JULAT_023'] = 1 if row['NGRI'] in pkis_list else 0\n",
    "    row['JULAT_024'] = 1 if row['NGRA'] in ngra_list else 0\n",
    "    row['JULAT_025'] = 1 if row['OKU'] in oku_list else 0\n",
    "    row['JULAT_026'] = 1 if row['P'] in [1, 2, 3, 4] else 0\n",
    "    row['JULAT_027'] = 1 if row['PT'] in pt_22_list else 0\n",
    "    row['JULAT_028'] = 1 if row['SJ'] in sj_22_list else 0\n",
    "    row['JULAT_029'] = 1 if row['IP'] in ip_list or pd.isna(row['IP']) else 0\n",
    "    row['JULAT_030'] = 1 if row['FS'] in fs_list else 0\n",
    "    row['JULAT_031'] = 1 if row['HMWA'] in hmwa_list else 0\n",
    "    \n",
    "    return row\n",
    "\n",
    "df = df.apply(validate_all_julats, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3621a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['S18', 'S19']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e72803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_status.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S18'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status['Kod'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['S18', 'S20']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b27a3aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amnar\\AppData\\Local\\Temp\\ipykernel_20044\\1075925437.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['MSIC_1D'] = df['S19'].map(df_msic.set_index('KOD_MSIC')['SEKSYEN'])\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df_msic = df_msic.drop_duplicates(subset='KOD_MSIC', keep='first')\n",
    "\n",
    "# Mapping column S19 with column KOD_MSIC and getting value from column SEKSYEN\n",
    "df['MSIC_1D'] = df['S19'].map(df_msic.set_index('KOD_MSIC')['SEKSYEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b0778b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amnar\\AppData\\Local\\Temp\\ipykernel_20044\\2510299594.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['MASCO_1D'] = df['S18'].map(df_masco.set_index('KOD_MASCO')['SECTION_1D'])\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df_masco = df_masco.drop_duplicates(subset='KOD_MASCO', keep='first')\n",
    "\n",
    "# Mapping column S19 with column KOD_MSIC and getting value from column SEKSYEN\n",
    "df['MASCO_1D'] = df['S18'].map(df_masco.set_index('KOD_MASCO')['SECTION_1D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ad5a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amnar\\AppData\\Local\\Temp\\ipykernel_20044\\3516098445.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['STATUS'] = df['S18'].map(df_status.set_index('S18')['STATUS'])\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df_status = df_status.drop_duplicates(subset='S18', keep='first')\n",
    "\n",
    "# Mapping column S19 with column KOD_MSIC and getting value from column SEKSYEN\n",
    "df['STATUS'] = df['S18'].map(df_status.set_index('S18')['STATUS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89006d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4821471",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ref = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cedacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------\n",
    "# # Konsistensi 1(a)\n",
    "# # -----------------------------------\n",
    "\n",
    "# # This function checks a condition based on the 'TK' and 'U' columns of the dataframe.\n",
    "# # If the difference between a reference year and the sum of these columns is greater than 3, \n",
    "# # it sets the value of 'KONSISTENSI_01a' to 0. Otherwise, it sets the value to 1.\n",
    "# def validate_condition_01(df, year_ref):\n",
    "#     def compute(row):\n",
    "#         if (year_ref - int(row['TK']) - int(row['U'])) > 3:\n",
    "#             return 0\n",
    "#         else:\n",
    "#             return 1\n",
    "    \n",
    "#     df['KONSISTENSI_01'] = df.apply(lambda row: compute(row) if row['TK'].isdigit() and row['U'].isdigit() else 0, axis=1).astype(int)\n",
    "\n",
    "# validate_condition_01(df, year_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi 1(a)\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_01(df, year_ref):\n",
    "    def compute(row):\n",
    "        try:\n",
    "            # Try to convert 'TK' and 'U' to integers\n",
    "            tk_value = int(row['TK'])\n",
    "            u_value = int(row['U'])\n",
    "            \n",
    "            # Check the condition\n",
    "            if (year_ref - tk_value - u_value) > 3:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        except ValueError:\n",
    "            # If there's an error converting to integer, return 0\n",
    "            return 0\n",
    "    \n",
    "    df['KONSISTENSI_01'] = df.apply(compute, axis=1).astype(int)\n",
    "\n",
    "validate_condition_01(df, year_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_01'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[df['KONSISTENSI_01'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi 1(b)\n",
    "# -----------------------------------\n",
    "\n",
    "# This function checks two conditions:\n",
    "# 1. If 'U' is less than or equal to 15, it sets 'KONSISTENSI_02' to 1.\n",
    "# 2. If 'U' is greater than 15 and 'HMWA' is not null, it sets 'KONSISTENSI_02' to 1.\n",
    "def validate_condition_02(df):\n",
    "    df['KONSISTENSI_02'] = 0\n",
    "    df.loc[df['U'].astype(int) <= 15, 'KONSISTENSI_02'] = 1\n",
    "    combined_condition = (df['U'].astype(int) > 15) & ~df['HMWA'].isnull()\n",
    "    df.loc[combined_condition, 'KONSISTENSI_02'] = 1\n",
    "\n",
    "validate_condition_02(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35518757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_02'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ab21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_condition_03(df, values):\n",
    "    # Start by setting all values in 'KONSISTENSI_03' to 1\n",
    "    df['KONSISTENSI_03'] = 1\n",
    "    \n",
    "    # Find rows where 'NGRA' is '458' and 'NGRI' is NOT in the list 'values'\n",
    "    mask = (df['NGRA'] == '458') & (~df['NGRI'].isin(values))\n",
    "    \n",
    "    # Set 'KONSISTENSI_03' to 0 for those rows\n",
    "    df.loc[mask, 'KONSISTENSI_03'] = 0\n",
    "\n",
    "ngri_lst = ['01', '02', '03', '04', '05', '06', '07', '08', '09',\n",
    "            '10', '11', '12', '13', '14', '15', '16', \n",
    "            '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',\n",
    "            '31', '59', '32', '33', '34', '35', '36', '37', '38', '39',\n",
    "            '40', '41', '42', '43', '44', '45', '46', '47', '48', '49',\n",
    "            '50', '51', '52', '53', '54', '55', '56', '57', '58']\n",
    "\n",
    "validate_condition_03(df, ngri_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90b286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_03'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e110d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi 1(c)\n",
    "# -----------------------------------\n",
    "\n",
    "# This function checks the values of 'NGRI' for rows where 'NGRA' is 458.\n",
    "# If 'NGRI' is not in the provided list of allowed values, it sets 'KONSISTENSI_03' to 0.\n",
    "def validate_condition_03(df, values):\n",
    "    df['KONSISTENSI_03'] = 1\n",
    "    df_ngra = df[df['NGRA'] == '458']\n",
    "    mask = ~df_ngra['NGRI'].isin(values)\n",
    "    df.loc[df_ngra[mask].index, 'KONSISTENSI_03'] = 0\n",
    "\n",
    "ngri_lst = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16']\n",
    "\n",
    "validate_condition_03(df, ngri_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_03'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi 1(d)\n",
    "# -----------------------------------\n",
    "\n",
    "# This function checks if values in the 'OKU' column are present in the provided list of OKU values.\n",
    "# If a match is found, it sets 'KONSISTENSI_04' to 1, otherwise 0.\n",
    "def validate_condition_04(df, oku_list):\n",
    "    df['KONSISTENSI_04'] = df['OKU'].astype(int).isin(oku_list).astype(int)\n",
    "\n",
    "oku_list = list(map(int, df_oku[\"Kod\"].values))\n",
    "validate_condition_04(df, oku_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "oku_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bca720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_04'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi 1(e)\n",
    "# -----------------------------------\n",
    "\n",
    "# This function checks if values in the 'KW' column are present in the provided list.\n",
    "# If a match is found, it sets 'KONSISTENSI_05a' to 1, otherwise 0.\n",
    "def validate_condition_05a(df, kw):\n",
    "    df['KONSISTENSI_05a'] = df['KW'].astype(str).isin(kw).astype(int)\n",
    "\n",
    "# This function checks if values in the 'KET' column are present in the provided list.\n",
    "# If a match is found, it sets 'KONSISTENSI_05b' to 1, otherwise 0.\n",
    "def validate_condition_05b(df, ket):\n",
    "    df['KONSISTENSI_05b'] = df['KET'].astype(int).isin(ket).astype(int)\n",
    "\n",
    "validate_condition_05a(df, kw_list)\n",
    "validate_condition_05b(df, ket_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37b966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['KONSISTENSI_05a'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caece5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_05b'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[df['KONSISTENSI_05b'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926441e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['KET'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c1776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KET'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e6643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d919d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PT'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee764b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi 1(f)\n",
    "# -----------------------------------\n",
    "\n",
    "# This function checks if any row of the dataframe meets any of the conditions specified in merged_conditions.\n",
    "# If a row meets any of the conditions, it sets 'KONSISTENSI_06' for that row to 1.\n",
    "def validate_condition_06(df, merged_conditions):\n",
    "    df['KONSISTENSI_06'] = 0\n",
    "    for index, row in df.iterrows():\n",
    "        for condition_key, condition_values in merged_conditions.items():\n",
    "            match = True\n",
    "            for col, val in condition_values.items():\n",
    "                if isinstance(val, list):\n",
    "                    if row[col] not in val:\n",
    "                        match = False\n",
    "                        break\n",
    "                else:\n",
    "                    if row[col] != val:\n",
    "                        match = False\n",
    "                        break\n",
    "            if match:\n",
    "                df.loc[index, 'KONSISTENSI_06'] = 1\n",
    "                break\n",
    "\n",
    "validate_condition_06(df, persekolahan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e411dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_06'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "persekolahan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb9b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['P', 'PT', 'U', 'SJ']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb2ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_list = list(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TP'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the rows that meet the first condition: 'S20' should be equal to 4.\n",
    "    filtered_data_TC8b = data[(data['S20'] == 4)].copy()\n",
    "\n",
    "    # For the filtered rows, if 'S19' is NaN, mark them as fail (KONSISTENSI_TC8b = 0).\n",
    "    data.loc[data.index.isin(filtered_data_TC8b.index) & data['S19'].isna(), 'KONSISTENSI_TC8b'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi 1(g)\n",
    "# -----------------------------------\n",
    "\n",
    "# This function checks two conditions:\n",
    "# 1. If 'U' is greater than or equal to 18, it sets 'KONSISTENSI_08' to 1.\n",
    "# 2. If 'U' is less than 18 and 'TP' are not equals to 1, it sets 'KONSISTENSI_08' to 0.\n",
    "def validate_condition_08(df):\n",
    "    # Initialize all values in 'KONSISTENSI_08' to 1 (default \"pass\" value)\n",
    "    df['KONSISTENSI_08'] = 1\n",
    "    \n",
    "    # Filter rows where 'U' is less than 18\n",
    "    filtered_condition = df['U'].astype(int) < 18\n",
    "    \n",
    "    # From the filtered data, find rows where 'TP' is 1\n",
    "    tp_condition = (df['TP'] == 1)\n",
    "    \n",
    "    # Set 'KONSISTENSI_08' to 0 for those rows\n",
    "    df.loc[tp_condition, 'KONSISTENSI_08'] = 0\n",
    "\n",
    "validate_condition_08(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_08'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[df['KONSISTENSI_08'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[['U', 'TP']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69714804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2c824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi 1(h)\n",
    "# -----------------------------------\n",
    "\n",
    "# This function checks two conditions:\n",
    "# 1. If 'U' is greater than 15 and 'HMWA' is not null.\n",
    "# 2. If the first condition is met, it further checks if 'HMWA' and 'HMIS\n",
    "\n",
    "def validate_condition_09(df):\n",
    "    df['KONSISTENSI_09'] = 0\n",
    "    condition_1 = (df['U'].astype(int) > 15) & ~df['HMWA'].isnull()\n",
    "    condition_2 = df['HMWA'] == df['HMIS']\n",
    "    df.loc[condition_1 & condition_2, 'KONSISTENSI_09'] = 1\n",
    "\n",
    "validate_condition_09(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSIC_1D'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d25bd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C1a\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC1a(data):\n",
    "    \"\"\"\n",
    "    Validate consistency for 'MSIC_1D', 'S19', and 'S20' in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'MSIC_1D', 'S19', and 'S20'\n",
    "                             columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC1a',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Initialize 'KONSISTENSI_TC1a' with 1 for all rows.\n",
    "    data['KONSISTENSI_TC1a'] = 1\n",
    "    \n",
    "    # Identify rows that need further validation based on 'MSIC_1D' and 'S19'.\n",
    "    filtered_rows = (\n",
    "        data['S19'].between('84111', '84300')\n",
    "    )\n",
    "    \n",
    "    # For the filtered rows, if 'S20' is not '2', mark them as fail (0).\n",
    "    data.loc[filtered_rows & (data['S20'] != '2'), 'KONSISTENSI_TC1a'] = 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC1a(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fec015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC1a'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[df['KONSISTENSI_TC1a'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[['S19', 'S20', 'S18']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C1b\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC1b(data):\n",
    "    \"\"\"\n",
    "    Validate consistency for 'MSIC_1D', 'S19', and 'KW' in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'MSIC_1D', 'S19', and 'KW'\n",
    "                             columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC1b',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Initialize 'KONSISTENSI_TC1b' with 1 for all rows.\n",
    "    data['KONSISTENSI_TC1b'] = 1\n",
    "    \n",
    "    # Identify rows that meet the filter criteria based on 'MSIC_1D' and 'S19'.\n",
    "    filtered_rows = data['S19'].between('84111', '84300')\n",
    "    \n",
    "    # For the filtered rows, if 'KW' is other than 458, mark them as fail (0).\n",
    "    fail_condition = filtered_rows & (data['KW'] != 458)\n",
    "    data.loc[fail_condition, 'KONSISTENSI_TC1b'] = 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC1b(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee40a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC1b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1186033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[df['KONSISTENSI_TC1b'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[['S19', 'KW']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f8586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ed245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6d2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C2\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC2(data):\n",
    "    \"\"\"\n",
    "    Validate consistency based on conditions for 'MSIC_1D' and 'S20'.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'MSIC_1D' and 'S20'\n",
    "                             columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC2',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Initialize 'KONSISTENSI_TC2' with 1 for all rows (assume pass initially).\n",
    "    data['KONSISTENSI_TC2'] = 1\n",
    "    \n",
    "    # Identify rows that need further validation based on 'MSIC_1D'.\n",
    "    filtered_data_TC2 = data[data['S19'].isin(['97000', '98100', '98200'])].copy()\n",
    "\n",
    "    \n",
    "    # For the filtered rows, if 'S20' is not 3 and not NaN, mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC2.index) & (data['S20'].astype(str) != '3') & (data['S20'].notna()), 'KONSISTENSI_TC2'] = 0      \n",
    "    \n",
    "    return data\n",
    "    \n",
    "result = validate_condition_TC2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4de2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[df['KONSISTENSI_TC2'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[['S19', 'S20', 'PKIS']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624face",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed21ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C3\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC3a(data):\n",
    "    \"\"\"\n",
    "    Validate consistency based on conditions for 'MSIC_1D' and 'S20'.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'MSIC_1D' and 'S20'\n",
    "                             columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC3',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Initialize 'KONSISTENSI_TC3' with 1 for all rows (assume pass initially).\n",
    "    data['KONSISTENSI_TC3a'] = 1\n",
    "    \n",
    "    # Identify rows that need further validation based on 'MSIC_1D'.\n",
    "    filtered_data_TC3 = data[data['S19'].isin([\"85101\", \"85103\", \"85211\", \"85221\", \"85301\"])].copy()\n",
    "    \n",
    "    # For the filtered rows, if 'S20' is not 2 and not NaN, mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC3.index) & (data['S20'].astype(str) != '2') & (data['S20'].notna()), 'KONSISTENSI_TC3a'] = 0             \n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC3a(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c830d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC3a'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result1 = df[df['KONSISTENSI_TC3a'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43131674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result1[['S19', 'S20']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbccdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fltrd_01 = df[df['S19'].isin([\"85102\", \"85104\", \"85212\", \"85222\", \"85302\"]) & \n",
    "                 (df['MSIC_1D'] == \"P\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fltrd_01[['S19', 'MSIC_1D']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5095399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C3\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC3b(data):\n",
    "    \"\"\"\n",
    "    Validate consistency based on conditions for 'MSIC_1D' and 'S20'.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'MSIC_1D' and 'S20'\n",
    "                             columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC3',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Initialize 'KONSISTENSI_TC3' with 1 for all rows (assume pass initially).\n",
    "    data['KONSISTENSI_TC3b'] = 1\n",
    "    \n",
    "    # Identify rows that need further validation based on 'MSIC_1D'.\n",
    "    filtered_data_TC3 = data[data['S19'].isin([\"85102\", \"85104\", \"85212\", \"85222\", \"85302\"])].copy()\n",
    "    \n",
    "    # For the filtered rows, if 'S20' is not 2 and not NaN, mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC3.index) & (data['S20'].astype(str) == '2'), 'KONSISTENSI_TC3b'] = 0             \n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC3b(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC3b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3678fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC3b'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2[['S19', 'S20']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464437f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637ad81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c116507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a04c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa9b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C4\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC4(data):\n",
    "    \"\"\"\n",
    "    Validate consistency based on conditions for 'MSIC_1D', 'MASCO_1D', and 'S20'.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'MSIC_1D', 'MASCO_1D', and 'S20' \n",
    "                             columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC4',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Initialize 'KONSISTENSI_TC4' with 1 for all rows (assume pass initially).\n",
    "    data['KONSISTENSI_TC4'] = 1\n",
    "    \n",
    "    # Identify rows that need further validation based on 'MSIC_1D' and 'MASCO_1D'.\n",
    "    filtered_data_TC4 = data[(data['MSIC_1D'] == 'A') & (data['MASCO_1D'] == 9)].copy()\n",
    "    \n",
    "    # For the filtered rows, if 'S20' is not 3, 4, or 5 and not NaN, mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC4.index) & (~data['S20'].isin(['3', '4', '5'])) & (data['S20'].notna()), 'KONSISTENSI_TC4'] = 0       \n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC4(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdee53f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec58edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC4'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e5aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea95ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583ecae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede908ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C5a\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC5a(data):\n",
    "    \"\"\"\n",
    "    Validate consistency based on conditions for 'S18' and 'SJ'.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'S18' and 'SJ' columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC5a',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Ensure 'SJ' is treated as a numeric column, converting invalid entries to NaN.\n",
    "    data['SJ'] = pd.to_numeric(data['SJ'], errors='coerce')\n",
    "    \n",
    "    # Initialize 'KONSISTENSI_TC5a' with 1 for all rows (assume pass initially).\n",
    "    data['KONSISTENSI_TC5a'] = 1\n",
    "    \n",
    "    # Identify rows that meet the first condition for further validation.\n",
    "    filtered_data_TC5a = data[(data['S18'] >= '111101') & (data['S18'] <= '291918')].copy()\n",
    "    \n",
    "    # For the filtered rows, if 'SJ' is NOT between 20 and 242 and is not NaN, \n",
    "    # and if column 'U' has values lesser than 45, mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC5a.index) & (data['SJ'].between(2, 22)) & (data['SJ'].notna()) & (data['U'] < '046'), 'KONSISTENSI_TC5a'] = 0       \n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC5a(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC5a'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53841d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC5a'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2[['S18', 'SJ', 'U']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d62fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C5b\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC5b(data):\n",
    "    \"\"\"\n",
    "    Validate consistency based on conditions for 'S18' and 'S20'.\n",
    "    \n",
    "    Conditions:\n",
    "    1. Rows where 'S18' is between '111101' and '291918' are considered for validation.\n",
    "    2. Initially, all entries are assumed to pass (KONSISTENSI_TC5b = 1).\n",
    "    3. Entries that fulfill condition 1 but have 'S20' equal to '4' are marked as fail (KONSISTENSI_TC5b = 0).\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'S18' and 'S20' columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC5b',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Ensure 'S18' and 'S20' are treated as strings.\n",
    "    data[['S18', 'S20']] = data[['S18', 'S20']].astype(str)\n",
    "    \n",
    "    # Initialize 'KONSISTENSI_TC5b' with 1 for all rows (assume pass initially).\n",
    "    data['KONSISTENSI_TC5b'] = 1\n",
    "    \n",
    "    # Identify rows that meet the first condition for further validation.\n",
    "    filtered_data_TC5b = data[data['S18'].between('111101', '291918')].copy()\n",
    "    \n",
    "    # For the filtered rows, if 'S20' is '4', mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC5b.index) & (data['S20'] == '4'), 'KONSISTENSI_TC5b'] = 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC5b(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC5b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4376f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC5b'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2[['S18', 'S20']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ae730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S20'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4091ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C6\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC6(data):\n",
    "    \"\"\"\n",
    "    Validate consistency based on conditions for 'STATUS' and 'S20'.\n",
    "    \n",
    "    Conditions:\n",
    "    1. Rows where 'S20' is equal to 2 are considered for validation.\n",
    "    2. Initially, all entries are assumed to pass (KONSISTENSI_TC6 = 1).\n",
    "    3. Entries that fulfill condition 1 but have 'STATUS' not equal to 'GOV' and not NaN are marked as fail (KONSISTENSI_TC6 = 0).\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing 'STATUS' and 'S20' columns to be validated.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'KONSISTENSI_TC6',\n",
    "                      indicating validation results.\n",
    "    \"\"\"\n",
    "    # Ensure 'S20' is treated as a string. 'STATUS' will also be treated as string but NaN will be kept as is.\n",
    "    data['S20'] = data['S20'].astype(str)\n",
    "    \n",
    "    # Initialize 'KONSISTENSI_TC6' with 1 for all rows (assume pass initially).\n",
    "    data['KONSISTENSI_TC6'] = 1\n",
    "    \n",
    "    # Identify rows that meet the first condition for further validation.\n",
    "    filtered_data_TC6 = data[data['STATUS'] == 'GOV'].copy()\n",
    "    \n",
    "    # For the filtered rows, if 'STATUS' is not 'GOV' and not NaN, mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC6.index) & ~(data['S20'] == '2'), 'KONSISTENSI_TC6'] = 0      \n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC6(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC6'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC6'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e12e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result2[['S18', 'STATUS', 'S20']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340cdd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae03b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S18'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50819817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_list_str = [str(item) for item in status_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723eb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_list_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c543591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C7\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC7(data, masco_list):\n",
    "    # Initialize a new column 'KONSISTENSI_TC7' and set it as 1 (pass) for all rows initially\n",
    "    data['KONSISTENSI_TC7'] = 1\n",
    "    \n",
    "    # Filter data according to the first condition\n",
    "    filtered_data_TC7 = data[(data['S20'] == '2')].copy()\n",
    "    \n",
    "    # Apply the second condition:\n",
    "    # For the filtered rows, if 'STATUS' is not 'GOV' and is not NaN, mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC7.index) & ~(data['S18'].isin(status_list_str)), 'KONSISTENSI_TC7'] = 0    \n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC7(df, masco_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb3acef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC7'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC7'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f2878b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result2[['S18', 'S20', 'STATUS']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86f30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb9772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab23ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311696a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ee0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc8a_list = ['85101', '85103', '85211', '85221', '85301']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C8a\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC8a(data):\n",
    "    \"\"\"\n",
    "    Validates the condition T-C8a.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The data on which to perform the validation.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The data with an additional column indicating the \n",
    "                      results of the validation.\n",
    "                      \n",
    "    Explanation:\n",
    "        - First Condition: \n",
    "            The data is filtered based on the condition (data['S20'] == 2). \n",
    "            Rows that do not satisfy this condition are considered as pass \n",
    "            (KONSISTENSI_TC8a = 1).\n",
    "            \n",
    "        - Second Condition: \n",
    "            From the filtered data, the 'S19' should be between '84111' and '84300' \n",
    "            (inclusive). If 'S19' is outside of this range, it's considered as fail \n",
    "            (KONSISTENSI_TC8a = 0). Otherwise, it's considered as pass (KONSISTENSI_TC8a = 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the new column with 1 (indicating pass) for all rows.\n",
    "    data['KONSISTENSI_TC8a'] = 1\n",
    "\n",
    "    # Identify the rows that meet the first condition: 'S20' should be equal to 2.\n",
    "    filtered_data_TC8a = data[(data['S20'] == '2')].copy()\n",
    "\n",
    "    # For the filtered rows, if 'S19' is outside the range '84111' to '84300', mark them as fail (KONSISTENSI_TC8a = 0).\n",
    "    data.loc[data.index.isin(filtered_data_TC8a.index) & ~(data['S19'].astype(str).between('84111', '84300')) & ~(data['S19'].isin(tc8a_list)), 'KONSISTENSI_TC8a'] = 0     \n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC8a(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e34e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC8a'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623aea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc8a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S20'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC8a'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a25ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result2[['S19', 'S20']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9924a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b90c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd125f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C8b\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC8b(data):\n",
    "    \"\"\"\n",
    "    Validates the condition T-C8b.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The data on which to perform the validation.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The data with an additional column indicating the \n",
    "                      results of the validation.\n",
    "                      \n",
    "    Explanation:\n",
    "        - First Condition: \n",
    "            The data is filtered based on the condition (data['S20'] == 4). \n",
    "            Rows that do not satisfy this condition are considered as pass \n",
    "            (KONSISTENSI_TC8b = 1).\n",
    "            \n",
    "        - Second Condition: \n",
    "            From the filtered data, if 'S19' is NaN (i.e., does not have a value), \n",
    "            it's considered as fail (KONSISTENSI_TC8b = 0). Otherwise, it's considered \n",
    "            as pass (KONSISTENSI_TC8b = 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    data['S20'] = data['S20'].astype(str)\n",
    "    \n",
    "    # Initialize the new column with 1 (indicating pass) for all rows.\n",
    "    data['KONSISTENSI_TC8b'] = 1\n",
    "\n",
    "    # Identify the rows that meet the first condition: 'S20' should be equal to 4.\n",
    "    filtered_data_TC8b = data[(data['S20'] == '4')].copy()\n",
    "\n",
    "    # For the filtered rows, if 'S19' is NaN, mark them as fail (KONSISTENSI_TC8b = 0).\n",
    "    data.loc[data.index.isin(filtered_data_TC8b.index), 'KONSISTENSI_TC8b'] = 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC8b(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC8b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b44b027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['S20'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S19'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3191705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC8b'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae034fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result2[['S19', 'S20']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea10ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b8ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0849be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RIN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb260ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "~(data['RIN'].isin(tc9_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7541da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc9_list = [6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b96d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C9\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC9(data):\n",
    "    \"\"\"\n",
    "    This function performs the T-C9 validation on the dataframe `data`.\n",
    "    \n",
    "    Parameters:\n",
    "        - data (pd.DataFrame): the input data to validate.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: the input dataframe with an additional column `KONSISTENSI_TC9`\n",
    "                      which indicates pass (1) or fail (0) for the validation.\n",
    "    \n",
    "    The validation conditions are as follows:\n",
    "        1. Filter rows with PKIS == 11. The rest are considered pass.\n",
    "        2. For the filtered rows from condition 1, if MSIC_1D is not 'T' and not NaN, mark them as fail (0).\n",
    "           If MSIC_1D is 'T' or NaN, they pass this validation stage (1).\n",
    "    \"\"\"\n",
    "    # Create a new column 'KONSISTENSI_TC9' and initialize it with 1 (pass)\n",
    "    data['KONSISTENSI_TC9'] = 1\n",
    "    \n",
    "    # First condition: Filter rows where 'PKIS' is 11\n",
    "    filtered_data_TC9 = data[data['PKIS'].astype(str) == '11'].copy()\n",
    "    \n",
    "    # Second condition:\n",
    "    # For the filtered rows, if 'MSIC_1D' is not 'T' and not NaN, mark them as fail (0).\n",
    "#     data.loc[data.index.isin(filtered_data_TC9.index) & (data['MSIC_1D'] != 'T') & (data['MSIC_1D'].notna()), 'KONSISTENSI_TC9'] = 0        \n",
    "#     data.loc[data.index.isin(filtered_data_TC9.index) & (data['MSIC_1D'] != 'T') & (data['MSIC_1D'].isna()), 'KONSISTENSI_TC9'] = 0\n",
    "    data.loc[data.index.isin(filtered_data_TC9.index) & (((data['MSIC_1D'] != 'T') & data['MSIC_1D'].notna()) | data['MSIC_1D'].isna()), 'KONSISTENSI_TC9'] = 0       \n",
    "\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC9(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd90894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC9'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ffef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC9'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2[['PKIS', 'MSIC_1D', 'RIN', 'NAMA']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ba958",
   "metadata": {},
   "outputs": [],
   "source": [
    "7227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1fa81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_001 = df.iloc[7725:7740]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d731f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_001[['PKIS', 'MSIC_1D', 'RIN', 'S18', 'NAMA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c8f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab91753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbabb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rin = 1, 2, 3, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C10\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC10(data):\n",
    "    \"\"\"\n",
    "    Validate the condition TC10 on the provided dataframe.\n",
    "\n",
    "    Condition:\n",
    "    1. First, filter the data where 'S19' is between '98100' and '98200'.\n",
    "    2. For the filtered data, if 'RIN' is NaN, it is considered pass (KONSISTENSI_TC10 = 1).\n",
    "       Else, it is considered fail (KONSISTENSI_TC10 = 0).\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The dataframe to validate.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with the validation results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the 'S19' column is a string, so we can perform string comparisons\n",
    "    data['S19'] = data['S19'].astype(str)\n",
    "    \n",
    "    # First condition: Filter data where 'S19' is between '98100' and '98200'\n",
    "    filtered_data_TC10 = data[data['S19'].between('98100', '98200')].copy()\n",
    "    \n",
    "    # Initialize a new column for the validation results and set to 1 as default (pass)\n",
    "    data['KONSISTENSI_TC10'] = 1\n",
    "    \n",
    "    # Second condition: For the filtered rows, if 'RIN' is not NaN, mark them as fail (0)\n",
    "    data.loc[data.index.isin(filtered_data_TC10.index) & data['RIN'].notna(), 'KONSISTENSI_TC10'] = 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC10(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244bdbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1377f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4722e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eddde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C11\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC11(data):\n",
    "    \"\"\"\n",
    "    Validate conditions for T-C11.\n",
    "    \n",
    "    The data is first filtered based on 'RIN' being between 1 and 5. Rows that do not\n",
    "    meet this condition are considered as 'pass' (KONSISTENSI_TC11 = 1).\n",
    "    \n",
    "    From the remaining filtered data, the function checks whether 'S19' equals '99000'.\n",
    "    If 'S19' is not '99000' or is NaN, it marks them as 'fail' (KONSISTENSI_TC11 = 0).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the 'RIN' and 'S19' columns are treated as strings for consistency in comparison\n",
    "    data['RIN'] = data['RIN'].astype(str)\n",
    "    data['S19'] = data['S19'].astype(str)\n",
    "    \n",
    "    # First condition: filter rows where 'RIN' is between '1' and '5'.\n",
    "    filtered_data_TC11 = data[data['RIN'].isin(['1.0', '2.0', '3.0'])].copy()\n",
    "    \n",
    "    # Initialize the validation column with 'pass' (1).\n",
    "    data['KONSISTENSI_TC11'] = 1\n",
    "    \n",
    "    # Second condition:\n",
    "    # For the filtered rows, if 'S19' is not '99000' and not NaN, mark them as 'fail' (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC11.index) & (data['S19'] =='99000'), 'KONSISTENSI_TC11'] = 0      \n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC11(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac67b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KONSISTENSI_TC11'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467bb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RIN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a913409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S19'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343864e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525cbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a2de94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9897, 103)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_TC12 = df[df['MASCO_1D'].notna() & df['MSIC_1D'].notna()].copy()      \n",
    "filtered_data_TC12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af94aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_TC12.isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76aff0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amnar\\AppData\\Local\\Temp\\ipykernel_20044\\3419814133.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['KONSISTENSI_TC12'] = 1\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C12\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC12(data):\n",
    "    \"\"\"\n",
    "    Validate the consistency of the data against conditions (T-C12).\n",
    "    \n",
    "    This function checks the data for the following consistency conditions:\n",
    "    - First, it filters the data for rows where 'MASCO_1D' and 'MSIC_1D' have non-NaN values.\n",
    "    - Then, it checks whether 'S19' is between '98100' and '98200' (inclusive) for the filtered data.\n",
    "      If 'S19' is within this range, the data does not meet the consistency requirement.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The data on which to perform the consistency check.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The original data with an additional column 'KONSISTENSI_TC12',\n",
    "                  indicating pass (1) or fail (0) for each row based on the consistency check.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First condition: \n",
    "    # Filter rows where both 'MASCO_1D' and 'MSIC_1D' have valid (non-NaN) values.\n",
    "    filtered_data_TC12 = data[data['MASCO_1D'].notna() & data['MSIC_1D'].notna()].copy()      \n",
    "    \n",
    "    # Initialize a new column 'KONSISTENSI_TC12' with 1 (indicating pass) for all rows.\n",
    "    data['KONSISTENSI_TC12'] = 1\n",
    "\n",
    "    # Second condition: \n",
    "    # For the filtered rows, if 'S19' is within the range ['98100', '98200'], mark them as fail (0).\n",
    "    data.loc[data.index.isin(filtered_data_TC12.index) & data['S19'].between('98100', '98200'), 'KONSISTENSI_TC12'] = 0        \n",
    "\n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC12(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b79bd48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KONSISTENSI_TC12\n",
       "1    27165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KONSISTENSI_TC12'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf104bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2[['PKIS', 'MSIC_1D', 'RIN', 'NAMA']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b99da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0979ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C13\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC13(data):\n",
    "    \"\"\"\n",
    "    Validate the data according to the T-C13 condition.\n",
    "    \n",
    "    Conditions:\n",
    "    1. First, filter the data where 'KW' is equal to 458. \n",
    "       If 'KW' is not equal to 458, the entry is considered as pass (KONSISTENSI_TC13 = 1).\n",
    "    2. From the filtered data, check if the 'KET' value is in the provided `ket_list`.\n",
    "       If 'KET' is NOT in `ket_list` or is NaN, it's considered a fail (KONSISTENSI_TC13 = 0).\n",
    "       Otherwise, it's considered a pass (KONSISTENSI_TC13 = 1).\n",
    "       \n",
    "    Parameters:\n",
    "    - data (DataFrame): The data on which to perform the validation.\n",
    "    - ket_list (list): A list of valid values for the 'KET' field.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: The data with an additional column 'KONSISTENSI_TC13' indicating pass/fail.\n",
    "    \"\"\"\n",
    "    # Ensure 'KW' and 'KET' are treated as strings\n",
    "    data['KW'] = data['KW'].astype(str)\n",
    "    data['KET'] = data['KET'].astype(str)\n",
    "    \n",
    "    # Initialize a new column for the validation results and set default as 1 (pass)\n",
    "    data['KONSISTENSI_TC13'] = 1\n",
    "    \n",
    "    # Identify rows that meet the first condition\n",
    "    condition_1 = (data['KW'] == '458')\n",
    "    \n",
    "    # For the rows meeting the first condition, if 'KET' is NOT in ket_list or is NaN, mark them as fail (0)\n",
    "    data.loc[condition_1 & (~data['KET'].isin(ket_list) | data['KET'].isna()), 'KONSISTENSI_TC13'] = 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC13(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12cd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae11b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4652642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amnar\\AppData\\Local\\Temp\\ipykernel_20044\\1865157590.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['KONSISTENSI_TC14'] = 1\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C14\n",
    "# -----------------------------------\n",
    "\n",
    "# TC-14: Jika Jantina (J) Lelaki (kod 1), \n",
    "#     check PKIS = 01 (Ketua Isi Rumah) dan S10 = 02 (kerja rumah/ tanggungjawab keluarga). \n",
    "#     Jika Umur (U) >= 50 boleh terima, tapi jika U < 50, semak semula\n",
    "\n",
    "def validate_condition_TC14(data):\n",
    "    \"\"\"\n",
    "    Validate the condition TC-14:\n",
    "    - First, filter rows where 'J' == '1', 'PKIS' == '01', and 'S10' == '2' (first condition).\n",
    "    - For the filtered rows, if 'U' < 50, mark them as fail (0).\n",
    "    \"\"\"\n",
    "    # Ensure the columns are in the correct data type\n",
    "    data['J'] = data['J'].astype(str)\n",
    "    data['PKIS'] = data['PKIS'].astype(str)\n",
    "    data['S10'] = data['S10'].astype(str)\n",
    "    data['U'] = pd.to_numeric(data['U'], errors='coerce')\n",
    "    \n",
    "    # Initialize a new column for the validation result and set default as 1 (pass)\n",
    "    data['KONSISTENSI_TC14'] = 1\n",
    "\n",
    "    # Filter the data to meet the first condition\n",
    "    filtered_data_TC14 = data[(data['J'] == '1') & (data['PKIS'] == '01') & (data['S10'] == '02')].copy()\n",
    "\n",
    "    # For the filtered rows, if 'U' < 50, mark them as fail (0)\n",
    "    data.loc[data.index.isin(filtered_data_TC14.index) & (data['U'] < 50), 'KONSISTENSI_TC14'] = 0\n",
    "\n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC14(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1477f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KONSISTENSI_TC14\n",
       "1    27137\n",
       "0       28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KONSISTENSI_TC14'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fa82ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 105)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC14'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e80a3f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PKIS</th>\n",
       "      <th>J</th>\n",
       "      <th>S10</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7335</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10139</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10791</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10860</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12795</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14286</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14495</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14539</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14555</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15149</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17083</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19434</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21105</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21141</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21636</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22548</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23620</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23916</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24050</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26137</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PKIS  J S10   U\n",
       "509     01  1  02  34\n",
       "2059    01  1  02  46\n",
       "2430    01  1  02  34\n",
       "5566    01  1  02  49\n",
       "5567    01  1  02  41\n",
       "5602    01  1  02  49\n",
       "7335    01  1  02  36\n",
       "9778    01  1  02  39\n",
       "10139   01  1  02  39\n",
       "10689   01  1  02  46\n",
       "10791   01  1  02  48\n",
       "10860   01  1  02  47\n",
       "12795   01  1  02  31\n",
       "14286   01  1  02  49\n",
       "14495   01  1  02  45\n",
       "14539   01  1  02  35\n",
       "14555   01  1  02  47\n",
       "15149   01  1  02  49\n",
       "17083   01  1  02  43\n",
       "19434   01  1  02  35\n",
       "21105   01  1  02  39\n",
       "21141   01  1  02  37\n",
       "21636   01  1  02  25\n",
       "22548   01  1  02  43\n",
       "23620   01  1  02  45\n",
       "23916   01  1  02  33\n",
       "24050   01  1  02  45\n",
       "26137   01  1  02  32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result2[['PKIS', 'J', 'S10', 'U']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a483c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccecea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Konsistensi T-C15a & T-C15b\n",
    "# -----------------------------------\n",
    "\n",
    "def validate_condition_TC15(data):\n",
    "    # Ensure the U column is treated as numeric\n",
    "    data['U'] = pd.to_numeric(data['U'], errors='coerce')\n",
    "    \n",
    "    # Initializing columns with 1 (pass)\n",
    "    data['KONSISTENSI_TC15a'] = 1\n",
    "    data['KONSISTENSI_TC15b'] = 1\n",
    "    \n",
    "    # First condition: T-C15a\n",
    "    # Filter where TP == 1 and PKIS is in ['02', '04', '05', '07', '08']\n",
    "    condition_TC15a = (data['TP'] == '1') & data['PKIS'].isin(['02', '04', '05', '07', '08'])\n",
    "    # Mark as fail (0) if the condition is met\n",
    "    data.loc[condition_TC15a, 'KONSISTENSI_TC15a'] = 0\n",
    "    \n",
    "    # Second condition: T-C15b\n",
    "    # Filter where TP in [2, 3, 4, 5] and U <= 17\n",
    "    condition_TC15b = data['TP'].isin(['2', '3', '4', '5']) & (data['U'] <= 17) & (data['P'] == '2')\n",
    "    # Mark as fail (0) if the condition is me\n",
    "    data.loc[condition_TC15b, 'KONSISTENSI_TC15b'] = 0\n",
    "    \n",
    "    # Combined condition: T-C15\n",
    "    # Initialize with 1 (pass)\n",
    "    data['KONSISTENSI_TC15'] = 1\n",
    "    # If either of the sub-conditions (T-C15a or T-C15b) is 0 (fail), mark T-C15 as 0 (fail)\n",
    "    data.loc[(data['KONSISTENSI_TC15a'] == 0) | (data['KONSISTENSI_TC15b'] == 0), 'KONSISTENSI_TC15'] = 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "result = validate_condition_TC15(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6c52d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KONSISTENSI_TC15b\n",
       "1    27164\n",
       "0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KONSISTENSI_TC15b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03e785fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 108)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result2 = df[df['KONSISTENSI_TC15b'] == 0]\n",
    "df_result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "041ff36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>PKIS</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22854</th>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TP PKIS   U\n",
       "22854  2   02  12"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result2[['TP', 'PKIS', 'U']].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e47a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d3266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e6bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "649376a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['S10'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d2640cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P\n",
       "4    16848\n",
       "2     7230\n",
       "1     3073\n",
       "3       14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38122605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3073, 111)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_TC16a = df[(df['P'] == '1')].copy()\n",
    "filtered_data_TC16a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1e88a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_condition_TC16a(data):\n",
    "    \"\"\"\n",
    "    Validate the consistency condition TC16a.\n",
    "    \n",
    "    Conditions:\n",
    "    - P = 1 (Not schooling)\n",
    "    - S10 = 01 and S15 = 1 OR S10 = 07 and S15 in [2, 3]\n",
    "    \n",
    "    If a row satisfies both conditions, it will be marked as fail (0).\n",
    "    Otherwise, it will be marked as pass (1).\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): The data to validate.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The data with a new column 'KONSISTENSI_TC16a' indicating pass/fail.\n",
    "    \"\"\"\n",
    "    # Filtering the data according to the specified conditions\n",
    "    filtered_data_TC16a = data[(data['P'] == '1')].copy()          \n",
    "    \n",
    "    # Initializing a new column with 1 (pass)\n",
    "    data['KONSISTENSI_TC16a'] = 1\n",
    "    \n",
    "    # Identify rows within the filtered data where 'S10' is neither '01' nor '07'\n",
    "    fail_rows = filtered_data_TC16a[~filtered_data_TC16a['S10'].isin(['01', '07'])].index\n",
    "    \n",
    "    # Marking the rows that fail the conditions as 0 (fail)\n",
    "    data.loc[fail_rows, 'KONSISTENSI_TC16a'] = 0\n",
    "    \n",
    "    # For the filtered rows, if 'U' < 50, mark them as fail (0)\n",
    "    data.loc[data.index.isin(filtered_data_TC16a.index) & data['S10'].isin(['01', '07']), 'KONSISTENSI_TC16a'] = 0          \n",
    "    \n",
    "    # Marking the rows that fail the conditions as 0 (fail)\n",
    "    data.loc[filtered_data_TC16a.index, 'KONSISTENSI_TC16a'] = 0\n",
    "\n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC16a(df)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def validate_condition_TC16b(data):\n",
    "    \"\"\"\n",
    "    Validate the consistency condition TC16b.\n",
    "    \n",
    "    Conditions:\n",
    "    - P = 2 (Schooling)\n",
    "    - S10 in [03, 08, 09, 12, 13]\n",
    "    \n",
    "    If a row satisfies both conditions, it will be marked as fail (0).\n",
    "    Otherwise, it will be marked as pass (1).\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): The data to validate.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The data with a new column 'KONSISTENSI_TC16b' indicating pass/fail.\n",
    "    \"\"\"\n",
    "    # Filtering the data according to the specified conditions\n",
    "    filtered_data_TC16b = data[\n",
    "        (data['P'] == 2) & \n",
    "        data['S10'].isin(['03', '08', '09', '12', '13'])\n",
    "    ].copy()\n",
    "    \n",
    "    # Initializing a new column with 1 (pass)\n",
    "    data['KONSISTENSI_TC16b'] = 1\n",
    "    \n",
    "    # Marking the rows that fail the conditions as 0 (fail)\n",
    "    data.loc[filtered_data_TC16b.index, 'KONSISTENSI_TC16b'] = 0\n",
    "\n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC16b(df)\n",
    "                               \n",
    "################################################################################\n",
    "\n",
    "def validate_condition_TC16c(data):\n",
    "    \"\"\"\n",
    "    Validate the consistency condition TC16c.\n",
    "    \n",
    "    Conditions:\n",
    "    - P = 4 (Finished school)\n",
    "    - S10 in [01, 07]\n",
    "    \n",
    "    If a row satisfies both conditions, it will be marked as fail (0).\n",
    "    Otherwise, it will be marked as pass (1).\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): The data to validate.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The data with a new column 'KONSISTENSI_TC16c' indicating pass/fail.\n",
    "    \"\"\"\n",
    "    # Filtering the data according to the specified conditions\n",
    "    filtered_data_TC16c = data[\n",
    "        (data['P'] == 4) & \n",
    "        data['S10'].isin(['01', '07'])\n",
    "    ].copy()\n",
    "    \n",
    "    # Initializing a new column with 1 (pass)\n",
    "    data['KONSISTENSI_TC16c'] = 1\n",
    "    \n",
    "    # Marking the rows that fail the conditions as 0 (fail)\n",
    "    data.loc[filtered_data_TC16c.index, 'KONSISTENSI_TC16c'] = 0\n",
    "\n",
    "    return data\n",
    "\n",
    "result = validate_condition_TC16c(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3577b45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KONSISTENSI_TC16b\n",
       "1    27165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KONSISTENSI_TC16b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11486022",
   "metadata": {},
   "outputs": [],
   "source": [
    "16a = 2\n",
    "16b = 22\n",
    "16c = 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3cdaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73358931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea004442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751119b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1cb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32196c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77ed7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(df):\n",
    "    # Filter the data to get only rows that contain 'RIN' == 1\n",
    "    df = df[df['RIN'] == '1'].copy()\n",
    "\n",
    "    # Iterate over every row and check the conditions\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        s8_result = row['S8'] in [1000, 200, 30, 4, 1004, 204, 34] if not np.isnan(row['S8']) else False\n",
    "        s18_result = len(str(row['S18'])) == 6\n",
    "        s19_result = len(str(row['S19'])) == 5\n",
    "        s20_result = row['S20'] in range(1, 7) if not np.isnan(row['S20']) else False\n",
    "\n",
    "        result = (\n",
    "            (row['S1'] == 1) and\n",
    "            (len(str(int(row['S3']))) == 2 and row['S3'] >= 30) and\n",
    "            (row['S7'] in [1, 2]) and\n",
    "            s8_result and\n",
    "            s18_result and\n",
    "            s19_result and\n",
    "            s20_result and\n",
    "            (row['S21'] in range(1, 4)) and\n",
    "            (row['S22'] in range(1, 4)) and\n",
    "            (row['S23'] in range(1, 12)) and\n",
    "            (row['S24'] in [1, 2]) and\n",
    "            (row['S34'] in [1, 2])\n",
    "        )\n",
    "        results.append(int(result))\n",
    "\n",
    "    # Add the results as a new column\n",
    "    df['combined_result'] = results\n",
    "\n",
    "    return df\n",
    "\n",
    "df = check_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fccd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = ('C:/Users/amnar/Desktop/gh_konsistensi/output/stb/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae97ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the original file name\n",
    "original_file_name = os.path.basename(dataset_path)\n",
    "\n",
    "suffix = '_konsistensi'\n",
    "\n",
    "# Create the new file name by adding the suffix and changing the extension to .xlsx\n",
    "new_file_name = original_file_name.replace('.xlsx', '') + suffix + '.xlsx'\n",
    "\n",
    "# Save the DataFrame to Excel using the new file name\n",
    "df_new.to_excel(os.path.join(output_file_path, new_file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f015cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the original file name\n",
    "original_file_name = os.path.basename(dataset_path)\n",
    "\n",
    "suffix = '_konsistensi'\n",
    "\n",
    "# Create the new file name by adding the suffix\n",
    "new_file_name = original_file_name.replace('.csv', '') + suffix + '.csv'\n",
    "\n",
    "# Save the DataFrame as CSV using the new file name\n",
    "df.to_csv(os.path.join(output_file_path, new_file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
